name: CI/CD Pipeline (Backend & Frontend → ECR → Terraform/EC2)

on:
  push:
    branches: [main]

concurrency:
  group: cicd-finalproject
  cancel-in-progress: true

jobs:
  test-backend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install dependencies
        run: |
          cd backend
          npm ci

      - name: Run backend tests
        run: |
          cd backend
          npm test

      - name: Run backend coverage
        run: |
          cd backend
          npm run test:coverage

      - name: Upload backend coverage report
        uses: actions/upload-artifact@v4
        with:
          name: backend-coverage
          path: backend/coverage/

  push-backend:
    runs-on: ubuntu-latest
    needs: test-backend
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Ensure backend ECR repo exists
        env:
          ECR_URI: ${{ secrets.ECR_REPO_BACKEND }}  # full URI, e.g. 012345678901.dkr.ecr.us-east-1.amazonaws.com/cicd-final-backend
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          set -euxo pipefail
          REPO_NAME="$(echo "$ECR_URI" | awk -F/ '{print $2}')"
          aws ecr describe-repositories --repository-names "$REPO_NAME" --region "$AWS_REGION" \
            || aws ecr create-repository --repository-name "$REPO_NAME" --region "$AWS_REGION"
          echo "BACKEND_IMAGE_URI=$ECR_URI" >> $GITHUB_ENV

      - name: ECR login (manual, retry)
        env:
          AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
          AWS_REGION:     ${{ secrets.AWS_REGION }}
        run: |
          set -euxo pipefail
          REGISTRY="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          for i in 1 2 3 4 5; do
            if aws ecr get-login-password --region "$AWS_REGION" | docker login --username AWS --password-stdin "$REGISTRY"; then
              echo "ECR login OK"
              break
            fi
            echo "ECR login failed (attempt $i); retrying..."
            sleep $((i*10))
            if [ $i -eq 5 ]; then echo "ECR login failed after retries"; exit 1; fi
          done

      - name: Build and push backend Docker image
        env:
          IMAGE_URI: ${{ env.BACKEND_IMAGE_URI }}
        run: |
          set -euxo pipefail
          export DOCKER_BUILDKIT=1
          docker build -t "$IMAGE_URI:latest" ./backend
          for i in 1 2 3 4 5; do
            docker push "$IMAGE_URI:latest" && break
            echo "docker push failed (attempt $i); retrying..."
            sleep $((i*10))
            if [ $i -eq 5 ]; then echo "push failed after retries"; exit 1; fi
          done

  push-frontend:
    runs-on: ubuntu-latest
    needs: test-backend
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Ensure frontend ECR repo exists
        env:
          ECR_URI: ${{ secrets.ECR_REPO_FRONTEND }}  # full URI
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          set -euxo pipefail
          REPO_NAME="$(echo "$ECR_URI" | awk -F/ '{print $2}')"
          aws ecr describe-repositories --repository-names "$REPO_NAME" --region "$AWS_REGION" \
            || aws ecr create-repository --repository-name "$REPO_NAME" --region "$AWS_REGION"
          echo "FRONTEND_IMAGE_URI=$ECR_URI" >> $GITHUB_ENV

      - name: ECR login (manual, retry)
        env:
          AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
          AWS_REGION:     ${{ secrets.AWS_REGION }}
        run: |
          set -euxo pipefail
          REGISTRY="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          for i in 1 2 3 4 5; do
            if aws ecr get-login-password --region "$AWS_REGION" | docker login --username AWS --password-stdin "$REGISTRY"; then
              echo "ECR login OK"
              break
            fi
            echo "ECR login failed (attempt $i); retrying..."
            sleep $((i*10))
            if [ $i -eq 5 ]; then echo "ECR login failed after retries"; exit 1; fi
          done

      - name: Build and push frontend Docker image
        env:
          IMAGE_URI: ${{ env.FRONTEND_IMAGE_URI }}
        run: |
          set -euxo pipefail
          export DOCKER_BUILDKIT=1
          docker build -t "$IMAGE_URI:latest" ./frontend
          for i in 1 2 3 4 5; do
            docker push "$IMAGE_URI:latest" && break
            echo "docker push failed (attempt $i); retrying..."
            sleep $((i*10))
            if [ $i -eq 5 ]; then echo "push failed after retries"; exit 1; fi
          done

  terraform-validate:
    runs-on: ubuntu-latest
    needs: [push-backend, push-frontend]
    steps:
      - uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Export AWS credentials
        run: |
          echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
          echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
          echo "AWS_REGION=${{ secrets.AWS_REGION }}" >> $GITHUB_ENV

      - name: Terraform Format (auto-fix)
        run: |
          cd infra/terraform
          terraform fmt -recursive

      - name: Terraform Validate
        run: |
          cd infra/terraform
          terraform init -backend=false -input=false
          terraform validate

      # Do not fail CI when plan reports changes (exit code 2)
      - name: Terraform Plan (non-fatal)
        run: |
          cd infra/terraform
          terraform init -input=false
          set +e
          terraform plan -no-color -detailed-exitcode -out=tfplan_validate
          code=$?
          set -e
          if [ $code -eq 0 ]; then
            echo "Plan: no changes."
            exit 0
          elif [ $code -eq 2 ]; then
            echo "Plan: changes detected (expected in validate stage)."
            exit 0
          else
            echo "Plan failed with exit code $code"
            exit $code
          fi

  deploy-ec2:
    runs-on: ubuntu-latest
    needs: terraform-validate
    steps:
      - uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      # Minimal safe cleanup to avoid name collisions
      - name: AWS Cleanup (idempotent)
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          set -euxo pipefail
          # delete colliding named TGs (ignore if absent)
          for TG in ec2-app-backend-tg ecs-app-tg ecs-backend-tg ec2-app-tg; do
            aws elbv2 delete-target-group --target-group-arn \
              "$(aws elbv2 describe-target-groups --names "$TG" --query 'TargetGroups[0].TargetGroupArn' --output text --region "$AWS_REGION" 2>/dev/null || echo "")" \
              --region "$AWS_REGION" || true
          done
          # delete a leftover ALB by name (ignore if absent)
          LB_ARN=$(aws elbv2 describe-load-balancers --names ec2-app-alb --query 'LoadBalancers[0].LoadBalancerArn' --output text --region "$AWS_REGION" 2>/dev/null || true)
          if [ -n "$LB_ARN" ] && [ "$LB_ARN" != "None" ]; then
            for L in $(aws elbv2 describe-listeners --load-balancer-arn "$LB_ARN" --query 'Listeners[*].ListenerArn' --output text --region "$AWS_REGION" 2>/dev/null || true); do
              aws elbv2 delete-listener --listener-arn "$L" --region "$AWS_REGION" || true
            done
            aws elbv2 delete-load-balancer --load-balancer-arn "$LB_ARN" --region "$AWS_REGION" || true
          fi
          # remove legacy IAM resources by name (ignore if absent)
          for ROLE in ec2-app-role ecsTaskExecutionRole; do
            aws iam get-role --role-name "$ROLE" >/dev/null 2>&1 || continue
            for P in $(aws iam list-attached-role-policies --role-name "$ROLE" --query 'AttachedPolicies[*].PolicyArn' --output text); do
              aws iam detach-role-policy --role-name "$ROLE" --policy-arn "$P" || true
            done
            aws iam delete-role --role-name "$ROLE" || true
          done

      - name: Terraform Apply
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          cd infra/terraform
          terraform init
          terraform apply -auto-approve
